{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from filelock import FileLock\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import torchvision\n",
    "import clip\n",
    "from clip_lt.utils.labels_names import labels_names\n",
    "import torch.nn as nn\n",
    "from clip_lt.blip.models.blip import blip_feature_extractor\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mrotem98\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.12.12 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.11"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/rotemisraeli/Documents/python/clip_lt/trainer/wandb/run-20220406_163623-3t1n0pmy</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/rotem98/clip_lt-trainer/runs/3t1n0pmy\" target=\"_blank\">dax-maquis-42</a></strong> to <a href=\"https://wandb.ai/rotem98/clip_lt-trainer\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_logger = WandbLogger()\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset_dir_path = '/Volumes/black_ssd/datasets/imagenet_lt/'\n",
    "# dataset_dir_path = '/Users/rotemisraeli/Documents/datasets/imagenet_lt/'\n",
    "\n",
    "model_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base.pth'\n",
    "image_size = 224\n",
    "\n",
    "class LightningMNISTClassifier(pl.LightningModule):\n",
    "    def __init__(self, config, data_dir=None):\n",
    "        super(LightningMNISTClassifier, self).__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.lr = config['lr']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.blip_model = blip_feature_extractor(pretrained=model_url, image_size=image_size, vit='base')\n",
    "        self.blip_model.eval()\n",
    "        self.blip_model.to(self.device)\n",
    "        self.text_features = torch.load('../text_features.pt')\n",
    "        self.text_features = self.text_features / self.text_features.norm(dim=-1, keepdim=True)\n",
    "        self.logit_scale = (nn.Parameter(torch.ones([]) * np.log(1 / 0.07))).exp()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(768,1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024,1000)\n",
    "        ).to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            image_features = self.blip_model(x, '', mode='image')[:,0]\n",
    "        # print(image_features.shape,x.shape)\n",
    "        out = self.fc(image_features)\n",
    "        out = out#.softmax(dim=-1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def old_forward(self, x):\n",
    "        image_features = self.clip_model.encode_image(x)\n",
    "        # normalized features\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # cosine similarity as logits\n",
    "        logits_per_image = self.logit_scale * image_features @ self.text_features.t()\n",
    "        logits_per_text = logits_per_image.t()\n",
    "        probs = logits_per_image#.softmax(dim=-1)\n",
    "        # print(probs.shape,probs)\n",
    "        return probs\n",
    "\n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "        return F.cross_entropy(logits, labels)\n",
    "\n",
    "    def accuracy(self, logits, labels):\n",
    "        _, predicted = torch.max(logits.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        accuracy = correct / len(labels)\n",
    "        return torch.tensor(accuracy)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        accuracy = self.accuracy(logits, y)\n",
    "\n",
    "        self.log(\"ptl/train_loss\", loss)\n",
    "        self.log(\"ptl/train_accuracy\", accuracy,prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        accuracy = self.accuracy(logits, y)\n",
    "        return {\"val_loss\": loss, \"val_accuracy\": accuracy}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x[\"val_accuracy\"] for x in outputs]).mean()\n",
    "        self.log(\"ptl/val_loss\", avg_loss)\n",
    "        self.log(\"ptl/val_accuracy\", avg_acc)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((image_size,image_size),interpolation=torchvision.transforms.functional.InterpolationMode.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "        ])\n",
    "        train_data = torchvision.datasets.ImageFolder(self.data_dir+'train/',transform=transform)\n",
    "        return DataLoader(train_data, batch_size=int(self.batch_size),num_workers=4,shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((image_size,image_size),interpolation=torchvision.transforms.functional.InterpolationMode.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "        ])\n",
    "        train_data = torchvision.datasets.ImageFolder(self.data_dir+'val/',transform=transform)\n",
    "        return DataLoader(train_data, batch_size=int(self.batch_size),num_workers=4)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.fc.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "def train_mnist(config):\n",
    "    model = LightningMNISTClassifier(config,data_dir=dataset_dir_path)\n",
    "    trainer = pl.Trainer(max_epochs=2, logger=wandb_logger)\n",
    "\n",
    "    trainer.fit(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def train_mnist_no_tune():\n",
    "    config = {\n",
    "        \"layer_1_size\": 128,\n",
    "        \"layer_2_size\": 256,\n",
    "        \"lr\": 4e-3,\n",
    "        \"batch_size\": 128\n",
    "    }\n",
    "    train_mnist(config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | blip_model | BLIP_Base  | 223 M \n",
      "1 | fc         | Sequential | 1.8 M \n",
      "------------------------------------------\n",
      "224 M     Trainable params\n",
      "0         Non-trainable params\n",
      "224 M     Total params\n",
      "899.478   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01c70ca7df5f4dcbb031bc48f2ec4205"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ade434c5f29411584370e088f7eb24e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "007cbcaf30b7431ca90dcde8a91f2fca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff671a9eddf349e2a470bd41d8a4eb6c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "train_mnist_no_tune() #115s/it 128 batch size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "texts = []\n",
    "for i in range(1000):\n",
    "    label_name = labels_names[i].split(',')[0]\n",
    "    if label_name[0] in 'aouie':\n",
    "        texts.append(f'a photo of an {label_name}')\n",
    "    else:\n",
    "        texts.append(f'a photo of a {label_name}')\n",
    "\n",
    "# texts2 = clip.tokenize(texts).to(device)\n",
    "# with torch.no_grad():\n",
    "#     text_features = model.encode_text(texts2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(text_features,'text_features2.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "texts[3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clip_model.visual.features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}